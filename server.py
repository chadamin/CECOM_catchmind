from fastapi import FastAPI, UploadFile, File
import torch
import clip
from PIL import Image
import io

app = FastAPI()

@app.get("/")
def root():
    return {"status": "server alive"}


# ğŸ”¹ CLIP ëª¨ë¸ì€ ì„œë²„ ì‹œì‘ ì‹œ 1ë²ˆë§Œ ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)


@app.post("/clip-test")
async def clip_test(image: UploadFile = File(...)):
    # ì´ë¯¸ì§€ ë¡œë“œ
    image_bytes = await image.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    image_input = preprocess(image).unsqueeze(0).to(device)

    # ğŸ”¹ CLIPì´ ë¹„êµí•  ë‹¨ì–´ë“¤ (ì›í•˜ë©´ ëŠ˜ë¦¬ê±°ë‚˜ êµì²´)
    candidates = [
        "cat",
        "dog",
        "car",
        "house",
        "tree",
        "person",
        "handwritten drawing"
    ]

    texts = [f"a drawing of a {c}" for c in candidates]
    text_tokens = clip.tokenize(texts).to(device)

    # CLIP ì¶”ë¡ 
    with torch.no_grad():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(text_tokens)
        similarity = (image_features @ text_features.T).softmax(dim=-1)[0]

    # ğŸ”¹ ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì–´ 1ê°œë§Œ ì„ íƒ
    best_idx = similarity.argmax().item()
    best_word = candidates[best_idx]
    best_score = float(similarity[best_idx])

    # ğŸ”¹ ì›¹ì—ì„œ ë°”ë¡œ ì“°ê¸° ì¢‹ì€ í˜•íƒœë¡œ ë°˜í™˜
    return {
        "guess": best_word,
        "confidence": round(best_score, 2)
    }
